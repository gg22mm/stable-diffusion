# model:
#   base_learning_rate: 2.0e-06
#   target: ldm.models.diffusion.ddpm.LatentDiffusion
#   params:
#     linear_start: 0.0015
#     linear_end: 0.0195
#     num_timesteps_cond: 1
#     log_every_t: 200
#     timesteps: 1000
#     first_stage_key: image
#     image_size: 64
#     channels: 3
#     monitor: val/loss_simple_ema
#     unet_config:
#       target: ldm.modules.diffusionmodules.openaimodel.UNetModel
#       params:
#         image_size: 64
#         in_channels: 3
#         out_channels: 3
#         model_channels: 224
#         attention_resolutions:
#         # note: this isn\t actually the resolution but
#         # the downsampling factor, i.e. this corresnponds to
#         # attention on spatial resolution 8,16,32, as the
#         # spatial reolution of the latents is 64 for f4
#         - 8
#         - 4
#         - 2
#         num_res_blocks: 2
#         channel_mult:
#         - 1
#         - 2
#         - 3
#         - 4
#         num_head_channels: 32
#     first_stage_config:
#       target: ldm.models.autoencoder.VQModelInterface
#       params:
#         embed_dim: 3
#         n_embed: 8192
#         # ckpt_path: configs/first_stage_models/vq-f4/model.yaml
#         ckpt_path: down_models/ldm/vq-f4/model.ckpt #https://ommer-lab.com/files/latent-diffusion/vq-f4.zip
#         ddconfig:
#           double_z: false
#           z_channels: 3
#           resolution: 256
#           in_channels: 3
#           out_ch: 3
#           ch: 128
#           ch_mult:
#           - 1
#           - 2
#           - 4
#           num_res_blocks: 2
#           attn_resolutions: []
#           dropout: 0.0
#         lossconfig:
#           target: torch.nn.Identity
#     cond_stage_config: __is_unconditional__
# data:
#   target: main.DataModuleFromConfig
#   params:
#     batch_size: 42
#     num_workers: 5
#     wrap: false
#     train:
#       target: ldm.data.faceshq.FFHQTrain
#       params:
#         size: 256
#     validation:
#       target: ldm.data.faceshq.FFHQValidation
#       params:
#         size: 256


# lightning:
#   callbacks:
#     image_logger:
#       target: main.ImageLogger
#       params:
#         batch_frequency: 5000
#         max_images: 8
#         increase_log_steps: False

#   trainer:
#     benchmark: True


######################################## 修改后的版本  ########################################
# model:
#   base_learning_rate: 0.0001
#   target: ldm.models.diffusion.ddpm.LatentDiffusion
#   params:
#     linear_start: 0.0015
#     linear_end: 0.015
#     num_timesteps_cond: 1
#     log_every_t: 200
#     timesteps: 1000

#     first_stage_key: image    
#     # first_stage_key: jpg
#     # cond_stage_key: nix

#     image_size: 48
#     channels: 16
#     monitor: val/loss_simple_ema
#     unet_config:
#       target: ldm.modules.diffusionmodules.openaimodel.UNetModel
#       params:
#         image_size: 48
#         in_channels: 16
#         out_channels: 16
#         model_channels: 448
#         attention_resolutions:        
#         - 4
#         - 2
#         - 1
#         num_res_blocks: 2
#         channel_mult:
#         - 1
#         - 2
#         - 3
#         - 4
#         num_head_channels: 32
#     first_stage_config:
#       target: ldm.models.autoencoder.AutoencoderKL
#       params:
#         embed_dim: 16        
#         ddconfig:
#           double_z: true
#           z_channels: 16
#           resolution: 256
#           in_channels: 3
#           out_ch: 3
#           ch: 128
#           ch_mult:
#           - 1
#           - 2
#           - 2
#           - 4
#           num_res_blocks: 2
#           attn_resolutions:
#           - 16
#           dropout: 0.0
#         lossconfig:
#           target: torch.nn.Identity
#     cond_stage_config: 
#       target: torch.nn.Identity
# data:
#   target: main.DataModuleFromConfig
#   params:
#     batch_size: 42
#     num_workers: 5
#     wrap: false
#     train:
#       target: ldm.data.faceshq.FFHQTrain
#       params:
#         size: 256
#     validation:
#       target: ldm.data.faceshq.FFHQValidation
#       params:
#         size: 256


# lightning:
#   callbacks:
#     image_logger:
#       target: main.ImageLogger
#       params:
#         batch_frequency: 5000
#         max_images: 8
#         increase_log_steps: False

#   trainer:
#     benchmark: True


################################# 原版 ###################################################


model:
  base_learning_rate: 0.0001
  target: ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    linear_start: 0.0015
    linear_end: 0.015
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: jpg
    cond_stage_key: nix
    image_size: 48
    channels: 16
    cond_stage_trainable: false
    conditioning_key: crossattn
    monitor: val/loss_simple_ema
    scale_by_std: false
    scale_factor: 0.22765929
    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        image_size: 48
        in_channels: 16
        out_channels: 16
        model_channels: 448
        attention_resolutions:
        - 4
        - 2
        - 1
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        - 3
        - 4
        use_scale_shift_norm: false
        resblock_updown: false
        num_head_channels: 32
        use_spatial_transformer: true
        transformer_depth: 1
        context_dim: 768
        use_checkpoint: true
    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        monitor: val/rec_loss
        embed_dim: 16
        ddconfig:
          double_z: true
          z_channels: 16
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 1
          - 2
          - 2
          - 4
          num_res_blocks: 2
          attn_resolutions:
          - 16
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    cond_stage_config:
      target: torch.nn.Identity


# 我添加的，但是报错
# data:
#   target: main.DataModuleFromConfig
#   params:
#     batch_size: 2
#     num_workers: 0
#     train:
#       # target: ldm.data.imagenet.ImageNetTrainWithDepth
#       target: ldm.data.imagenet.ImageNetSRTrain
#       params:
#         size: 256
#     validation:
#       # target: ldm.data.imagenet.ImageNetValidationWithDepth
#       target: ldm.data.imagenet.ImageNetSRValidation
#       params:
#         size: 256